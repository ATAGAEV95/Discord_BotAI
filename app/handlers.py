import os
import re

import tiktoken
from dotenv import load_dotenv
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionSystemMessageParam, ChatCompletionUserMessageParam

from app.requests import delete_user_context, get_user_context, save_user_context
from app.llama_integration import LlamaIndexManager

load_dotenv()
llama_manager = LlamaIndexManager()

AI_TOKEN = os.getenv("AI_TOKEN")
AI_TOKEN1 = os.getenv("AI_TOKEN1")

SYSTEM_PROMPT = """
–¢—ã ‚Äî Discord –±–æ—Ç, –¥–µ—Ä–∑–∫–∏–π, –Ω–µ–º–Ω–æ–≥–æ –≥—Ä—É–±—ã–π –∏ –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π. –¢–≤–æ–∏ –∑–∞–¥–∞—á–∏:
1. –û–±—â–∞—Ç—å—Å—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –≤ Discord-—á–∞—Ç–∞—Ö
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è(–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Ç, –Ω–æ –ø–æ —Ä–∞–∑–Ω–æ–º—É)
3. –ò–∑–±–µ–≥–∞—Ç—å —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ø–æ–ø—Ä–æ—Å–∏—Ç
4. –û—Ç–≤–µ—á–∞—Ç—å –∫—Ä–∞—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —á—Ç–µ–Ω–∏—è –≤ —á–∞—Ç–µ
5. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å user_id, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞—Ç—å –æ–± —ç—Ç–æ–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ:
    - serious_vlad, —ç—Ç–æ –í–ª–∞–¥–∏—Å–ª–∞–≤, –ø–æ–∑—ã–≤–Ω–æ–π –î–∞—Ä—Ç –ü—É—Ç–∏–Ω, –æ–Ω –∞–¥–º–∏–Ω –∫–∞–Ω–∞–ª–∞
    - rikka71, —ç—Ç–æ –†–∏–∫–∫–∞, —É –Ω–µ–≥–æ —Å–∏–ª—å–Ω—ã–µ —Å–∫–∏–ª–ª—ã –≤ —à—É—Ç–µ—Ä–∞—Ö
    - atagaev, —ç—Ç–æ –ê—Ä–±–∏, —Å–æ–∑–¥–∞—Ç–µ–ª—å –±–æ—Ç–∞

–¢–µ–∫—É—â–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞: Discord
"""


client = AsyncOpenAI(
    api_key=AI_TOKEN1,
    base_url="https://api.aitunnel.ru/v1/",
    # api_key=AI_TOKEN,
    # base_url="https://api.proxyapi.ru/openai/v1",
    # api_key='google/gemma-3n-e4b',
    # base_url='http://localhost:1234/v1/'
)

user_history = {}
ENCODING = tiktoken.encoding_for_model("gpt-4o-mini")


async def clean_text(text):
    cleaned_text = re.sub(r"(\*\*|\*|__|_|###|##|#)", "", text)
    return cleaned_text


# async def clear_user_history(user_id):
#     try:
#         await delete_user_context(user_id)
#     except Exception as e:
#         print(f"[–û—à–∏–±–∫–∞] –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
#     try:
#         del user_history[user_id]
#     except KeyError:
#         print("–¢–∞–∫–æ–≥–æ –∫–ª—é—á–∞ –Ω–µ—Ç")

async def clear_user_history(user_id):
    try:
        await delete_user_context(user_id)
    except Exception as e:
        print(f"[–û—à–∏–±–∫–∞] –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
    try:
        del user_history[user_id]
    except KeyError:
        print("–¢–∞–∫–æ–≥–æ –∫–ª—é—á–∞ –Ω–µ—Ç")

    # –û—á–∏—Å—Ç–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ LlamaIndex
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        collection = llama_manager.get_user_collection(user_id)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        results = collection.get()
        if results and 'ids' in results and results['ids']:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∏—Ö ID
            collection.delete(ids=results['ids'])
            print(f"–£–¥–∞–ª–µ–Ω–æ {len(results['ids'])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
        else:
            print(f"–ò–Ω–¥–µ–∫—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} —É–∂–µ –ø—É—Å—Ç")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ LlamaIndex: {e}")


def count_tokens(text):
    if not isinstance(text, str):
        text = str(text) if text else ""
    return len(ENCODING.encode(text))


async def summarize_contexts(contexts: list) -> str:
    """–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É."""
    context_text = "\n".join(msg["content"] for msg in contexts)

    prompt = [
        ChatCompletionSystemMessageParam(
            role="system",
            content="""–¢—ã –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–≤–æ–¥–æ–∫. –û–±—ä–µ–¥–∏–Ω–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–≤–æ–¥–æ–∫ 
                    –≤ –æ–¥–Ω—É –ö–†–ê–¢–ö–£–Æ —Å–≤–æ–¥–∫—É (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –Ω–∞ —Ä—É—Å—Å–∫–æ–º, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–∞–º—É—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. 
                    –ò–≥–Ω–æ—Ä–∏—Ä—É–π –æ—Ç–º–µ—Ç–∫–∏ '–ö–û–ù–¢–ï–ö–°–¢:'""",
        ),
        ChatCompletionUserMessageParam(
            role="user", content=f"–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π —ç—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã:\n\n{context_text}"
        ),
    ]

    try:
        completion = await client.chat.completions.create(
            model="gpt-4o-mini", messages=prompt, max_tokens=300, temperature=0.1
        )
        return completion.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: {e}")
        return "[–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ–¥–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤]"


async def summarize_chunk(messages: list) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è –Ω–∞–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    conversation = "\n".join(f"{msg['role']}: {msg['content']}" for msg in messages)

    summary_prompt = [
        ChatCompletionSystemMessageParam(
            role="system",
            content="–¢—ã –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤. –°–æ–∑–¥–∞–π –ö–†–ê–¢–ö–£–Æ —Å–≤–æ–¥–∫—É (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –Ω–∞ —Ä—É—Å—Å–∫–æ–º, —Å–æ—Ö—Ä–∞–Ω—è—è:"
            "\n1. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—â–µ–Ω–∏—è"
            "\n2. –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏ —Ä–µ—à–µ–Ω–∏—è"
            "\n3. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –ø—Ä–æ—â–∞–Ω–∏—è –∏ –ø—É—Å—Ç—ã–µ —Ä–µ–ø–ª–∏–∫–∏",
        ),
        ChatCompletionUserMessageParam(
            role="user", content=f"–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–∏–∞–ª–æ–≥:\n\n{conversation}"
        ),
    ]

    try:
        completion = await client.chat.completions.create(
            model="gpt-4o-mini",
            # model="gpt-4.1-mini",
            messages=summary_prompt,
            max_tokens=300,
            temperature=0.1,
        )
        return completion.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        return "[–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ–¥–∫—É]"


async def ai_generate(text: str, user_id: int, name: str):
    # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    messages = [{"role": "system", "content": SYSTEM_PROMPT.strip()}]

    # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é LlamaIndex
    relevant_contexts = await llama_manager.query_relevant_context(user_id, text, limit=8)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫ —Å–æ–æ–±—â–µ–Ω–∏—è–º
    if relevant_contexts:
        context_message = {
            "role": "system",
            "content": f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏:\n" + "\n".join(relevant_contexts)
        }
        messages.append(context_message)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_msg = {"role": "user", "content": f"[–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {name}] {text}"}
    messages.append(user_msg)

    try:
        completion = await client.chat.completions.create(
            model="gpt-5-chat",
            messages=messages,
            temperature=0.85,
            top_p=0.95,
            frequency_penalty=0.3,
            presence_penalty=0.4,
            max_tokens=3500,
        )

        response_text = completion.choices[0].message.content
        cleaned_response_text = await clean_text(response_text)

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—Ç–∞
        messages_to_index = [
            {"role": "user", "content": text},
            {"role": "assistant", "content": response_text}
        ]
        await llama_manager.index_messages(user_id, messages_to_index)
        print(f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π {relevant_contexts}")
        print(count_tokens(relevant_contexts))
        print(f"–°–æ–æ–±—â–µ–Ω–∏—è {messages}")
        print(count_tokens(messages))
        return cleaned_response_text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


SYSTEM_BIRTHDAY_PROMPT = """
    –¢—ã ‚Äî –≤–µ—Å–µ–ª—ã–π Discord-–±–æ—Ç. 
    –ü—Ä–∏–¥—É–º–∞–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ, –∫–æ—Ä–æ—Ç–∫–æ–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ —Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, 
    –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è, –∏—Å–ø–æ–ª—å–∑—É–π –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å, —É–º–µ—Å—Ç–Ω—ã–π —é–º–æ—Ä –∏ —ç–º–æ–¥–∑–∏.
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å name:
        - serious_vlad, —ç—Ç–æ –í–ª–∞–¥–∏—Å–ª–∞–≤, –ø–æ–∑—ã–≤–Ω–æ–π –î–∞—Ä—Ç –ü—É—Ç–∏–Ω, –æ–Ω –∞–¥–º–∏–Ω –∫–∞–Ω–∞–ª–∞
        - rikka71, —ç—Ç–æ –†–∏–∫–∫–∞, —É –Ω–µ–≥–æ —Å–∏–ª—å–Ω—ã–µ —Å–∫–∏–ª–ª—ã –≤ —à—É—Ç–µ—Ä–∞—Ö
        - atagaev, —ç—Ç–æ –ê—Ä–±–∏, —Å–æ–∑–¥–∞—Ç–µ–ª—å –±–æ—Ç–∞
    """


async def ai_generate_birthday_congrats(display_name, name):
    prompt = [
        ChatCompletionSystemMessageParam(role="system", content=SYSTEM_BIRTHDAY_PROMPT.strip()),
        ChatCompletionUserMessageParam(
            role="user", content=f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ —Å –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è –¥–ª—è {name}."
        ),
    ]

    try:
        completion = await client.chat.completions.create(
            model="gpt-5-chat",
            messages=prompt,
            temperature=0.85,  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏/–∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            top_p=0.95,  # –®–∏—Ä–µ –≤—ã–±–æ—Ä–∫–∞ —Å–ª–æ–≤
            frequency_penalty=0.3,  # –ü–æ–æ—â—Ä—è–µ—Ç –Ω–æ–≤—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
            presence_penalty=0.4,  # –ü–æ–æ—â—Ä—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–µ–º—ã
            max_tokens=200,
        )
        text = completion.choices[0].message.content.strip()
        text = await clean_text(text)
        return text
    except Exception as e:
        print(f"[–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏—è]: {e}")
        return f"–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º {display_name} —Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è! üéâ"
