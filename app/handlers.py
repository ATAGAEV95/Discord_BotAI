import os
import re

import tiktoken
from dotenv import load_dotenv
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionSystemMessageParam, ChatCompletionUserMessageParam

from app.llama_integration import LlamaIndexManager

load_dotenv()
llama_manager = LlamaIndexManager()

AI_TOKEN = os.getenv("AI_TOKEN")
AI_TOKEN1 = os.getenv("AI_TOKEN1")

SYSTEM_PROMPT = """
–¢—ã ‚Äî Discord –±–æ—Ç, –¥–µ—Ä–∑–∫–∏–π, –Ω–µ–º–Ω–æ–≥–æ –≥—Ä—É–±—ã–π –∏ –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π. –¢–≤–æ–∏ –∑–∞–¥–∞—á–∏:
1. –û–±—â–∞—Ç—å—Å—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –≤ Discord-—á–∞—Ç–∞—Ö
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è(–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Ç, –Ω–æ –ø–æ —Ä–∞–∑–Ω–æ–º—É)
3. –ò–∑–±–µ–≥–∞—Ç—å —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ø–æ–ø—Ä–æ—Å–∏—Ç
4. –û—Ç–≤–µ—á–∞—Ç—å –∫—Ä–∞—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —á—Ç–µ–Ω–∏—è –≤ —á–∞—Ç–µ
5. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å name(–æ–Ω–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å –ø–æ –±—É–∫–≤–µ–Ω–æ, –∏–Ω–∞—á–µ —ç—Ç–æ –¥—Ä—É–≥–æ–π —é–∑–µ—Ä), –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞—Ç—å –æ–± —ç—Ç–æ–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ:
    - serious_vlad, —ç—Ç–æ –í–ª–∞–¥–∏—Å–ª–∞–≤, –ø–æ–∑—ã–≤–Ω–æ–π –î–∞—Ä—Ç –ü—É—Ç–∏–Ω, –æ–Ω –∞–¥–º–∏–Ω –∫–∞–Ω–∞–ª–∞
    - rikka71, —ç—Ç–æ –†–∏–∫–∫–∞, —É –Ω–µ–≥–æ —Å–∏–ª—å–Ω—ã–µ —Å–∫–∏–ª–ª—ã –≤ —à—É—Ç–µ—Ä–∞—Ö
    - atagaev, —ç—Ç–æ –ê—Ä–±–∏, —Å–æ–∑–¥–∞—Ç–µ–ª—å –±–æ—Ç–∞

–¢–µ–∫—É—â–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞: Discord
"""


client = AsyncOpenAI(
    api_key=AI_TOKEN1,
    base_url="https://api.aitunnel.ru/v1/",
    # api_key=AI_TOKEN,
    # base_url="https://api.proxyapi.ru/openai/v1",
    # api_key='google/gemma-3n-e4b',
    # base_url='http://localhost:1234/v1/'
)

ENCODING = tiktoken.encoding_for_model("gpt-4o-mini")


async def clean_text(text):
    cleaned_text = re.sub(r"(\*\*|\*|__|_|###|##|#)", "", text)
    return cleaned_text


async def clear_server_history(server_id):
    try:
        collection = llama_manager.get_server_collection(server_id)  # –ò–∑–º–µ–Ω—è–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
        results = collection.get()
        if results and 'ids' in results and results['ids']:
            collection.delete(ids=results['ids'])
            return f"–£–¥–∞–ª–µ–Ω–æ {len(results['ids'])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ —Å–µ—Ä–≤–µ—Ä–∞ {server_id}"
        else:
            return f"–ò–Ω–¥–µ–∫—Å —Å–µ—Ä–≤–µ—Ä–∞ {server_id} —É–∂–µ –ø—É—Å—Ç"
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ LlamaIndex: {e}")


def count_tokens(text):
    if not isinstance(text, str):
        text = str(text) if text else ""
    return len(ENCODING.encode(text))


async def ai_generate(text: str, server_id: int, name: str):
    messages = [{"role": "system", "content": SYSTEM_PROMPT.strip()}]

    relevant_contexts = await llama_manager.query_relevant_context(server_id, text, limit=8)

    if relevant_contexts:
        context_message = {
            "role": "system",
            "content": f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Å–µ—Ä–≤–µ—Ä–∞:\n" + "\n".join(relevant_contexts)
        }
        messages.append(context_message)

    user_msg = {"role": "user", "content": f"[–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {name}] {text}"}
    messages.append(user_msg)

    try:
        completion = await client.chat.completions.create(
            model="gpt-5-mini",
            messages=messages,
            temperature=1.2,
            top_p=0.95,
            frequency_penalty=0.3,
            presence_penalty=0.4,
            max_tokens=3500,
        )

        response_text = completion.choices[0].message.content
        cleaned_response_text = await clean_text(response_text)

        messages_to_index = [
            {"role": "user", "content": f"[–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {name}] {text}"},
            {"role": "assistant", "content": response_text}
        ]
        await llama_manager.index_messages(server_id, messages_to_index)
        print(f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π {relevant_contexts}")
        print(count_tokens(relevant_contexts))
        print(f"–°–æ–æ–±—â–µ–Ω–∏—è {messages}")
        print(count_tokens(messages))
        return cleaned_response_text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


SYSTEM_BIRTHDAY_PROMPT = """
    –¢—ã ‚Äî –≤–µ—Å–µ–ª—ã–π Discord-–±–æ—Ç. 
    –ü—Ä–∏–¥—É–º–∞–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ, –∫–æ—Ä–æ—Ç–∫–æ–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ —Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, 
    –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è, –∏—Å–ø–æ–ª—å–∑—É–π –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å, —É–º–µ—Å—Ç–Ω—ã–π —é–º–æ—Ä –∏ —ç–º–æ–¥–∑–∏.
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å name:
        - serious_vlad, —ç—Ç–æ –í–ª–∞–¥–∏—Å–ª–∞–≤, –ø–æ–∑—ã–≤–Ω–æ–π –î–∞—Ä—Ç –ü—É—Ç–∏–Ω, –æ–Ω –∞–¥–º–∏–Ω –∫–∞–Ω–∞–ª–∞
        - rikka71, —ç—Ç–æ –†–∏–∫–∫–∞, —É –Ω–µ–≥–æ —Å–∏–ª—å–Ω—ã–µ —Å–∫–∏–ª–ª—ã –≤ —à—É—Ç–µ—Ä–∞—Ö
        - atagaev, —ç—Ç–æ –ê—Ä–±–∏, —Å–æ–∑–¥–∞—Ç–µ–ª—å –±–æ—Ç–∞
    """


async def ai_generate_birthday_congrats(display_name, name):
    prompt = [
        ChatCompletionSystemMessageParam(role="system", content=SYSTEM_BIRTHDAY_PROMPT.strip()),
        ChatCompletionUserMessageParam(
            role="user", content=f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ —Å –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è –¥–ª—è {name}."
        ),
    ]

    try:
        completion = await client.chat.completions.create(
            model="gpt-5-chat",
            messages=prompt,
            temperature=0.85,  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏/–∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            top_p=0.95,  # –®–∏—Ä–µ –≤—ã–±–æ—Ä–∫–∞ —Å–ª–æ–≤
            frequency_penalty=0.3,  # –ü–æ–æ—â—Ä—è–µ—Ç –Ω–æ–≤—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
            presence_penalty=0.4,  # –ü–æ–æ—â—Ä—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–µ–º—ã
            max_tokens=200,
        )
        text = completion.choices[0].message.content.strip()
        text = await clean_text(text)
        return text
    except Exception as e:
        print(f"[–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏—è]: {e}")
        return f"–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º {display_name} —Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è! üéâ"
